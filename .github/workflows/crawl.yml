name: crawl

on:
  workflow_dispatch:
    inputs:
      start_date:
        description: 'Start date'
      end_date:
        description: 'End date'
  schedule:
    - cron: "0 3 * * *"

jobs:
  crawl:
    environment: crawl
    runs-on: ubuntu-latest
    # container: alephdata/memorious:latest
    services:
      redis:
        image: redis:alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v1
        with:
          python-version: "3.9"
      - name: Install dependencies
        env:
          DEBIAN_FRONTEND: noninteractive
        run: |
          sudo apt-get install -y -qq libicu-dev
          pip install --no-cache-dir -q pyicu awscli
          make install
      - name: Pull metadata
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: make mmmeta.pull
      - name: Run crawler
        env:
          MEMORIOUS_DATASTORE_URI: ${{ secrets.MEMORIOUS_DATASTORE_URI }}
          STARTDATE: ${{ github.event.inputs.start_date }}
          ENDDATE: ${{ github.event.inputs.end_date }}
          ARCHIVE_TYPE: ${{ secrets.ARCHIVE_TYPE }}
          ARCHIVE_BUCKET: ${{ secrets.ARCHIVE_BUCKET }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          REDIS_URL: redis://localhost:6379/0
        run: make run
      - name: Update metadata
        run: make mmmeta.generate
      - name: Push new files and metadata
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: make mmmeta.push
